---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Ontology Indentification and Utility Functions"
event: Intro to AI Alignment Lecture 
event_url: https://stanford.zoom.us/rec/play/s0Hd83CFErGM6F_Uv3Y-gewFUjSgRKTEx8cDDo6uTsBvaL9J_RBJuSFYLTHiQQ6UKJuX112lTV7GanR_.K3cV7GDy-kkDRo2-?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fstanford.zoom.us%2Frec%2Fshare%2FIjaUw43rXg4l4vzE_4AJ7cUjDCbIeCZznLrYlWiKq26RdO2i6oPEuWsbbq7pdfY9.7fNlXx-9nkQQwauH
location: 450 Jane Stanford Way, Stanford, CA 94305
address:
  street:
  city:
  region:
  postcode:
  country:
summary:

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: 2023-11-02T12:00:00-13:00
date_end: 2023-11-02T12:00:00-13:00
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: 2024-01-01T12:00:00-13:00

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code:
url_pdf:
url_video:

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

## Abstract:
For STS 10SI -- Intro to AI Alignment in Winter 2023 I talked eliciting latent knowledge, cooperative inverse reinforcement learning, and shard theory. First I introduce the ELK problem as formulated by Paul Christiano and I go through the main proposals and counterexamples from the [ELK document](https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.kkaua0hwmp1d). Then we introduce inverse reinforcement learning, cooperative inverse reinforcement learning, and their relationship to the alignment problem. We proceed with a discussion of whether humans can be thought of as having utility functions, leading into a conversation about Shard theory. Lastly, we talk about similarities between the limbic-cortex relationship and the alignment problem, and frame utility functions as a story the brain tells about itself. Slides [here](https://docs.google.com/presentation/d/1xqwf099kLXGqkgX5VUHMoIerAUS-Th90SMNZjIH6Bkg/edit?usp=sharing).

<iframe
  src="https://stanford.zoom.us/rec/play/s0Hd83CFErGM6F_Uv3Y-gewFUjSgRKTEx8cDDo6uTsBvaL9J_RBJuSFYLTHiQQ6UKJuX112lTV7GanR_.K3cV7GDy-kkDRo2-?canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fstanford.zoom.us%2Frec%2Fshare%2FIjaUw43rXg4l4vzE_4AJ7cUjDCbIeCZznLrYlWiKq26RdO2i6oPEuWsbbq7pdfY9.7fNlXx-9nkQQwauH"
  width="640"
  height="480"
  allow="autoplay; fullscreen;"
></iframe>
